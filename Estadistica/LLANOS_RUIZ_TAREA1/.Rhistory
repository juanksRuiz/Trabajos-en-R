Mn <- s*(1.0/n)
return(n)
}
Mn <- MediaMuestral(10)
#Promedio de la exponencial
Ex <- 1/0.1
derr <- abs(Mn-Ex)/Ex
Errores <- vector('numeric',100)
for (i in 1:length(Errores)) {
Mn <- MediaMuestral(10)
Errores[i] <- abs(Mn-Ex)/Ex
}
qa <- quantile(Errores,seq(0.9,1,0.01))
qa
Errores
Mn
#a)
MediaMuestral <- function(n){
X <-  rexp(n,0.1)
s <- 0
for (i in 1:n) {
s <- s + X[i]
}
Mn <- s*(1.0/n)
return(Mn)
}
Mn <- MediaMuestral(10)
#Promedio de la exponencial
Ex <- 1/0.1
derr <- abs(Mn-Ex)/Ex
Errores <- vector('numeric',100)
for (i in 1:length(Errores)) {
Mn <- MediaMuestral(10)
Errores[i] <- abs(Mn-Ex)/Ex
}
qa <- quantile(Errores,seq(0.9,1,0.01))
qa
#Percentil 95
p95 <- qa[6]
hist(Errores)
?hist
hist(Errores)
?hist
hist(Errores,plot = FALSE)
hist(Errores,plot = TRUE)
source('~/Desktop/Trabajos-en-R/HOYOS_RUIZ_tarea4_punto1.R')
qb1
pb1
hist(Errores2)
Errores3 <- VectorErrores(100,10000,10)
qb2 <- quantile(Errores3,seq(0.95,0.96,0.01))
pb2 <- qb2[1]
hist(Errores2)
hist(Errores3)
?hist
hist(Errores3,breaks = seq(0,0.5,0.001)
hist(Errores3,breaks = seq(0,0.5,0.001))
hist(Errores3)
hist(Errores,plot = TRUE)
hist(Errores2,plot=TRUE)
hist(Errores3,plot=TRUE)
#b.1)
Errores2 <- VectorErrores(100,1000,10)
qb1 <- quantile(Errores2,seq(0.95,0.96,0.01))
pb1 <- qb1[1]
hist(Errores2,plot=TRUE)
hist(Errores3,plot=TRUE)
hist(Errores3,plot=TRUE,xlab = 'Errores')
2**2
?rnorm()
Comparar <- function(n,I){
dif <- vector('numeric',I)
for( i in 1:I){
Errores <- VectorErrores(1000,n,0)
qz <- quantile(ErroresZ,seq(0.6,0.7,0.1))
p60 = qz[1]
N <- rnorm(n,0,1)
qN <- quantile(N,seq(0.95,0.96,0.001))
p95 <- qN[1]
dif[i] = abs(p60-p95)/p95
}
return(dif)
}
ErroresZ <- VectorErrores(1000,10,0)
qz <- quantile(ErroresZ,seq(0.6,0.7,0.1))
ErroresZ
VectorErrores <- function(k,n,promTeo){
#Retorna lista con k elementos de los errores relativos
Err <- vector('numeric',k)
for(i in 1:k){
Mn <- MediaMuestral(n)
Err[i] = abs(Mn-promTeo)
}
return(Err)
}
Mn <- MediaMuestral(10)
#Promedio de la exponencial
Ex <- 1/0.1
derr <- abs(Mn-Ex)/Ex
Errores <- vector('numeric',100)
for (i in 1:length(Errores)) {
Mn <- MediaMuestral(10)
Errores[i] <- abs(Mn-Ex)/Ex
}
qa <- quantile(Errores,seq(0.9,1,0.01))
#Percentil 95
p95 <- qa[6]
hist(Errores,plot = TRUE,'Diferencia errores')
#Percentil 95
p95 <- qa[6]
hist(Errores,plot = TRUE,'Diferencia errores')
hist(Errores,plot = TRUE,'Diferencia errores')
source('~/Desktop/Trabajos-en-R/HOYOS_RUIZ_tarea4_punto1.R', encoding = 'UTF-8')
hist(Errores)
#b.1)
Errores2 <- VectorErrores(100,1000,10)
qb1 <- quantile(Errores2,seq(0.95,0.96,0.01))
pb1 <- qb1[1]
hist(Errores2,plot=TRUE,'Diferencia errores')
hist(Errores2)
hist(Errores3)
#c)
Zn <- function(n,promTeo,sd){
#promTeo y sd son de X
Mn = MediaMuestral(n)
Zn <- (Mn - promTeo)/(sd/(n**0.5))
return(Zn)
}
Comparar <- function(n,I){
dif <- vector('numeric',I)
for( i in 1:I){
Errores <- VectorErrores(1000,n,0)
qz <- quantile(ErroresZ,seq(0.6,0.7,0.1))
p60 = qz[1]
N <- rnorm(n,0,1)
qN <- quantile(N,seq(0.95,0.96,0.001))
p95 <- qN[1]
dif[i] = abs(p60-p95)/p95
}
return(dif)
}
ErroresZ <- VectorErrores(1000,10,0)
qz <- quantile(ErroresZ,seq(0.6,0.7,0.1))
p60 = qz[1]
# I= 1
dif1 <- Comparar(10,1)
#b)
dif2 <- Comparar(10,100)
hist(dif2)
dif3 <- Comparar(1000,100)
hist(dif3)
dif4 <- Comparar(10000,100)
hist(dif4)
#b)
dif2 <- Comparar(10,100)
hist(dif2)
dif
hist(dif2)
hist(dif3)
hist(dif4)
dif4 <- Comparar(1000000,100)
dif4 <- Comparar(10000,100)
?hist()
hist(dif2,title('Histograma de errores teoricos con n = 10'))
hist(dif2,title('Histograma con n = 10'))
hist(dif2)
rm(list = ls())
library(plyr)
install.packages("plyr")
install.packages("readxl")
install.packages("RcppRoll")
install.packages("reshape2")
install.packages("tidyverse")
install.packages("lubridate")
install.packages("forecast")
install.packages("polynom")
install.packages("urca")
install.packages("Rssa")
install.packages("lmtest")
install.packages("tseries")
install.packages("seasonal")
library(plyr)
library(readxl)
library(RcppRoll)
library(reshape2)
library(tidyverse)
library(lubridate)
library(forecast)
library(polynom)
library(urca)
library(Rssa)
library(lmtest)
library(tseries)
library(seasonal)
info <- read_excel("~/TO.xlsx")
info <- read_excel("Documents/TO.xlsx")
info <- read_excel("Documents/TO.xlsx")
info$mes <- ymd(info$mes)
info %>% ggplot(aes(x = mes, y = ocupación)) + geom_line(size = 1, color = "#A52A2A") +
labs(title = "Tasa de Ocupación",
subtitle = "Total Nacional",
x = "Tiempo",
y = "Porcentaje  (%)",
caption = "Fuente: Dane") +
theme_bw() +
scale_x_date(date_breaks = "12 months", date_labels = "%b %y")
info %>% mutate(o_ocup = ocupación - lag(ocupación)) %>% ggplot(aes(x = mes, y = o_ocup)) + geom_line(size = 1, color = "#A52A2A") +
labs(title = "Cambio mensual en la tasa de ocupación",
subtitle = "Total Nacional",
x = "Tiempo",
y = "Porcentaje  (%)",
caption = "Fuente: Dane") +
theme_bw() +
scale_x_date(date_breaks = "12 months", date_labels = "%b %y")
ggtsdisplay(diff(ts(info$ocupación, start = c(2011,1), frequency = 12)), main = "Cambio mensual en la tasa de ocupacion", plot.type = "histogram")
gglagplot(diff(ts(info$ocupación, start = c(2011,1), frequency = 12)), 12, do.lines = FALSE) + labs(subtitle = "Gráfico de dispersión", title = "Cambio mensual en la tasa de desempleo")
ggseasonplot(diff(ts(info$ocupación, start = c(2011,1), frequency = 12))) + labs(subtitle = "Gráfico de estaciones", title = "Cambio mensual en la tasa de desempleo")
timeseries <- ts(info$ocupación, frequency = 12)
plot(timeseries)
timeseries <- tsclean(timeseries)
diffts <- diff(timeseries)
difftscomponent <- decompose(diffts)
autoplot(info)
autoplot(timeseries)
xdxd <- decompose(timeseries, type = "multiplicative")
# Perform seasonal decomposition on the data with both decompose
# and stl:
d1 <- stats::decompose(nottem)
d2 <- stats::stl(nottem, s.window = "periodic", robust = TRUE)
View(d1)
class(nottem)
cbind(broom::tidy(nottem), broom::augment(d1),
broom::augment(d2))
# Visually compare seasonal decompositions in tidy data frames.
library(tibble)
library(dplyr)
library(tidyr)
library(ggplot2)
decomps <- tibble(
# Turn the ts objects into data frames.
series = list(as.data.frame(nottem), as.data.frame(nottem)),
# Add the models in, one for each row.
decomp = c("decompose", "stl"),
model = list(d1, d2)
) %>%
rowwise() %>%
# Pull out the fitted data using broom::augment.
mutate(augment = list(broom::augment(model))) %>%
ungroup() %>%
# Unnest the data frames into a tidy arrangement of
# the series next to its seasonal decomposition, grouped
# by the method (stl or decompose).
group_by(decomp) %>%
unnest(series, augment) %>%
mutate(index = 1:n()) %>%
ungroup() %>%
select(decomp, index, x, adjusted = .seasadj)
ggplot(decomps) +
geom_line(aes(x = index, y = x), colour = "black") +
geom_line(aes(x = index, y = adjusted, colour = decomp,
group = decomp))
timeseries <- ts(info$ocupación, frequency = 12)
plot(timeseries)
timeseries <- tsclean(timeseries)
diffts <- diff(timeseries)
difftscomponent <- stats::decompose(diffts)
adjusted_diffts <- diffts - difftscomponent$seasonal
acf(adjusted_diffts)
pacf(adjusted_diffts)
class(nottem)
rm(list = ls())
library(plyr)
library(readxl)
library(RcppRoll)
library(reshape2)
library(tidyverse)
library(lubridate)
library(forecast)
library(polynom)
library(urca)
library(Rssa)
library(lmtest)
library(tseries)
library(seasonal)
info <- read_excel("Documents/TO.xlsx")
info$mes <- ymd(info$mes)
info %>% ggplot(aes(x = mes, y = ocupación)) + geom_line(size = 1, color = "#A52A2A") +
labs(title = "Tasa de Ocupación",
subtitle = "Total Nacional",
x = "Tiempo",
y = "Porcentaje  (%)",
caption = "Fuente: Dane") +
theme_bw() +
scale_x_date(date_breaks = "12 months", date_labels = "%b %y")
info %>% mutate(o_ocup = ocupación - lag(ocupación)) %>% ggplot(aes(x = mes, y = o_ocup)) + geom_line(size = 1, color = "#A52A2A") +
labs(title = "Cambio mensual en la tasa de ocupación",
subtitle = "Total Nacional",
x = "Tiempo",
y = "Porcentaje  (%)",
caption = "Fuente: Dane") +
theme_bw() +
scale_x_date(date_breaks = "12 months", date_labels = "%b %y")
ggtsdisplay(diff(ts(info$ocupación, start = c(2011,1), frequency = 12)), main = "Cambio mensual en la tasa de ocupacion", plot.type = "histogram")
gglagplot(diff(ts(info$ocupación, start = c(2011,1), frequency = 12)), 12, do.lines = FALSE) + labs(subtitle = "Gráfico de dispersión", title = "Cambio mensual en la tasa de desempleo")
ggseasonplot(diff(ts(info$ocupación, start = c(2011,1), frequency = 12))) + labs(subtitle = "Gráfico de estaciones", title = "Cambio mensual en la tasa de desempleo")
timeseries <- ts(info$ocupación, frequency = 12)
plot(timeseries)
timeseries <- tsclean(timeseries)
diffts <- diff(timeseries)
difftscomponent <- stats::decompose(diffts)
adjusted_diffts <- diffts - difftscomponent$seasonal
acf(adjusted_diffts)
pacf(adjusted_diffts)
ggtsdisplay(timeseries)
ggtsdisplay(adjusted_diffts)
summary(m1 <- Arima(adjusted_diffts, order = c(1,1,1), include.mean = F)) # AR(1)
coeftest(m1)
f1 <- forecast(m1, h = 10)
plot(f1)
ts_ocup  <- ts(info$ocupación, frequency = 12, start = c(2011,1))
ggtsdisplay(ts_ocup)
summary(ur.df(adjusted_diffts, type = "trend", lags = 12, selectlags = "BIC"))
summary(ur.df(adjusted_diffts, type = "drift", lags = 12, selectlags = "BIC"))
summary(ur.df(adjusted_diffts, type = "none", lags = 12, selectlags = "BIC"))
View(difftscomponent)
qnorm
qnorm(20)
qnorm(5)
qnorm(0.55)
qnorm(0.23)
license()
clc
clear
close()
close.connection()
library(readr)
ks_projects_201801 <- read_csv("Downloads/kickstarter-projects/ks-projects-201801.csv")
View(ks_projects_201801)
mtcars
n = c(2,3,5)
n
s = c("aa","bb","cc")
s
b = c(TRUE, FALSE, FALSE)
B
b
df = data.frame(n,s,b)
df
df[0]
df
df[1]
df[:3]
df[s]
df.kernel()
df
df[1][4]
nrow(df)
ncol(df)
head(df)
df[[2]]
df[,2]
df[,1]
df[2,]
df[bb]
df
df[n]
help("library")
library(iris)
library(datasets)
data("iris")
View(iris)
summary(iris)
head(iris)
mean(iris$Sepal.Length)
count(iris)
nrow(iris)
xBar <- sum(iris$Sepal.Length)/nrow(iris)
xBar
qnorm(0.05)
qnorm(0.95)
help(qnorm)
sqrt(4)
xBar <- sum(iris$Sepal.Length)/nrow(iris)
sdXbar <- sqrt(var(iris$Sepal.Length)/nrow(iris))
xRR <- (xBar - mean(iris$Sepal.Length))/sdXbar
xRR < qnorm(0.95)
mean(iris$Sepal.Length)
summary(iris)
matrix(summary(iris))
summary(iris)
AD(soft_fail_proj)
#Confugurando el espacio de trabajo
rm(list = ls())
#setwd("C:/Users/juank/Desktop/Trabajos-en-R/Estadistica/LLANOS_RUIZ_TAREA1")
# en linux
setwd("~/Desktop/Trabajos-en-R/Estadistica/LLANOS_RUIZ_TAREA1")
projects_df <- read.csv(file="ks_projects_201801.csv",header = TRUE,sep = ',')
#-----------------------------------
#Funciones
AD <- function(col){
#Retorna vector con estadistica descriptiva de la columna de datos
res <- c(summary(col), var(col), sd(col))
return(res)
}
AD(soft_fail_proj)
soft_fail_proj <- subset(subset(projects_df, category == "Software"),state == "failed")$usd_pledged_real
AD(soft_fail_proj)
AD <- function(col){
#Retorna vector con estadistica descriptiva de la columna de datos
res <- c(summary(col), var(col), sd(col))
return(res)
}
AD(iris$Sepal.Length)
data <- c(AD(iris$Sepal.Length),AD(iris$Sepal.Width),AD(iris$Petal.Length),
AD(iris$Petal.Width))
data
matData <- matrix(data,nrow = 4,byrow = TRUE)
matData
summary(iris)
rownames(matData) <- c("Min","1st qu","Median","Mean","3rd qu,","Max","Var","sd")
rownames(matData) <- c("Min","1st qu","Median","Mean","3rd qu,","Max","Var","sd")
matData <- matrix(data,nrow = 4,byrow = TRUE)
rownames(matData) <- c("Min","1st qu","Median","Mean","3rd qu,","Max","Var","sd")
matData
summary(iris)
colnames(matData) <- c("Min","1st qu","Median","Mean","3rd qu,","Max","Var","sd")
rownames(matData) <- c("Sepal length","Sepal width","Petal length", "Petal width")
matData
xRR <- (xBar - 6)/sdXbar
# H0: mu = 6
# Ha: mu > 6
# Estadistico de prueba: xBar
# Region de rechazo
# Nivel de confianza de 0.95 : alfa = 0.05
rm(list = ls())
library(datasets)
data("iris")
AD <- function(col){
#Retorna vector con estadistica descriptiva de la columna de datos
res <- c(summary(col), var(col), sd(col))
return(res)
}
matData <- matrix(data,nrow = 4,byrow = TRUE)
AD <- function(col){
#Retorna vector con estadistica descriptiva de la columna de datos
res <- c(summary(col), var(col), sd(col))
return(res)
}
data <- c(AD(iris$Sepal.Length),AD(iris$Sepal.Width),AD(iris$Petal.Length),
AD(iris$Petal.Width))
matData <- matrix(data,nrow = 4,byrow = TRUE)
colnames(matData) <- c("Min","1st qu","Median","Mean","3rd qu,","Max","Var","sd")
rownames(matData) <- c("Sepal length","Sepal width","Petal length", "Petal width")
xBar <- sum(iris$Sepal.Length)/nrow(iris)
sdXbar <- sqrt(var(iris$Sepal.Length)/nrow(iris))
xRR <- (xBar - 6)/sdXbar
xRR < qnorm(0.95)
xRR > qnorm(0.95)
xRR <- (xBar + 6)/sdXbar
xRR > qnorm(0.95)
6+qnorm(0.95)*sdXbar
xRR <- (xBar + 6)/sdXbar
xRR <- (xBar - 6)/sdXbar
xRR > qnorm(0.95)
#con la forma normal
6+qnorm(0.95)*sdXbar
#con la forma estandarizada
xRR <- (xBar - 6)/sdXbar
qnorm(0.95)
qnorm(-0.95)
qnorm(0.05)
#con la forma estandarizada
xRR <- (xBar - 6)/sdXbar
#con la forma normal
6+qnorm(0.95)*sdXbar
#calculando el intervalo de confianza
IntervalConfNorm(iris$Sepal.Length, xBar, 0.05,sdxbar)
IntervalConfNorm <-function(col,estim,alfa,sdEstimador){
lowIC <- estim - qnorm(1-alfa/2)*sdEstimador/(sqrt(nrow(col)))
upIC <-  estim + qnorm(1-alfa/2)*sdEstimador/(sqrt(nrow(col)))
return(c(lowIC,upIC))
}
#calculando el intervalo de confianza
IntervalConfNorm(iris$Sepal.Length, xBar, 0.05,sdxbar)
sdXbar <- sqrt(var(iris$Sepal.Length)/nrow(iris))
#calculando el intervalo de confianza
IntervalConfNorm(iris$Sepal.Length, xBar, 0.05,sdxbar)
#calculando el intervalo de confianza
IntervalConfNorm(iris$Sepal.Length, xBar, 0.05,sdXbar)
nrow(iris$Sepal.Length)
nrow(iris)
typeof(iris)
typeof(iris$Sepal.Length)
iris$Sepal.Length
#calculando el intervalo de confianza
IntervalConfNorm(iris$Sepal.Length, xBar, 0.05,sdXbar)
IntervalConfNorm <-function(col,estim,alfa,sdEstimador){
lowIC <- estim - qnorm(1-alfa/2)*sdEstimador/(sqrt(length(col)))
upIC <-  estim + qnorm(1-alfa/2)*sdEstimador/(sqrt(length(col)))
return(c(lowIC,upIC))
}
#calculando el intervalo de confianza
IntervalConfNorm(iris$Sepal.Length, xBar, 0.05,sdXbar)
#calculando el intervalo de confianza
IC_sepalIlength <- ntervalConfNorm(iris$Sepal.Length, xBar, 0.05,sdXbar)
#calculando el intervalo de confianza
IC_sepalIlength <- IntervalConfNorm(iris$Sepal.Length, xBar, 0.05,sdXbar)
#calculando el intervalo de confianza
IC_sepalLength <- IntervalConfNorm(iris$Sepal.Length, xBar, 0.05,sdXbar)
rnorm(data)
dnorm(10)
dnorm(data)
